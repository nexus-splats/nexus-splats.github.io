<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="icon" href="assets/logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="/style.css"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NexusSplats: Efficient 3D Gaussian Splatting in the Wild</title>
    <meta name="description"
          content="NexusSplats paper. Official web with qualitative comparisons, links to the source code, and additional materials.">
    <meta name="keywords" content="nexus-splats,3dgs,official,code"/>
    <meta name="author" content="Yuzhou Tang"/>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400..700;1,400..700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/@tabler/icons-webfont@latest/dist/tabler-icons.min.css" rel="stylesheet">
</head>
<body>
<header>
    <h1>
        <span class="title-main">
            <img src="assets/logo.png" alt="NexusSplats logo"/>
            <span>NexusSplats: Efficient 3D Gaussian Splatting in the Wild</span>
        </span>
    </h1>
<!--    <div class="conference">CVPR 2025</div>-->
</header>
<div class="authors">
    <div class="author">
        <span class="author-name">
            <a href="https://juliantang324.github.io/">Yuzhou Tang</a>
        </span>
    </div>
    <div class="author">
        <span class="author-name">
            <a href="https://orcid.org/0000-0001-6272-0941">Dejun Xu</a>
        </span>
    </div>
    <div class="author">
        <span class="author-name">
            <a href="https://github.com/Maximilian1794">Yongjie Hou</a>
        </span>
    </div>
    <div class="author">
        <span class="author-name">
            <a href="https://zhenzhongxmu.github.io/">Zhenzhong Wang</a>
        </span>
    </div>
    <div class="author">
        <span class="author-name">
            <a href="https://minjiang.xmu.edu.cn/">Min Jiang</a>
        </span>
    </div>
</div>
<div class="author-affiliation">
    <span>Xiamen University</span>
</div>
<div class="links">
    <a class="button" href="https://arxiv.org/pdf/2411.14514"><i class="ti ti-file-type-pdf"></i> Paper</a>
    <a class="button" href="https://github.com/juliantang324/NexusSplats"><i class="ti ti-brand-github-filled"></i> Code</a>
</div>
<video class="video" style="aspect-ratio: 1920/1080" loop muted autoplay>
    <source src="/assets/cover-trevi.mp4" type="video/mp4">
</video>
<p class="justify" style="margin: 0.2em 0 0.4rem 0; text-align-last: center">
    <em>NexusSplats</em> enables efficient and finer 3D scene reconstruction under complex lighting and occlusion.
</p>

<section class="abstract">
    <h2>Abstract</h2>
    <p>
        We propose a nexus kernel-driven approach, called <em>NexusSplats</em>, for efficient and finer 3D scene reconstruction
        under complex lighting and occlusion conditions. Experimental results demonstrate that NexusSplats achieves
        state-of-the-art rendering quality and reduces reconstruction time in different scenes by up to 70.4% compared
        to the current best method in quality.
    </p>
    <figure style="margin-top: 2em">
        <img src="assets/overview.png" alt="NexusSplats overview"
             style="width: 100%; margin: 1em auto 0.3em auto; display: block;"/>
        <figcaption style="margin-top: 1em">
            <strong>Overview of <em>NexusSplats</em></strong>. <strong>Left:</strong> From the reference image, we extract light embedding and transient embedding to capture
            global lighting and occlusion conditions. <strong>Middle:</strong> Our nexus kernels enable hierarchical management
            of Gaussian primitives, allowing efficient local adaptations to different lighting and occlusion conditions
            via the light decoupling module and the uncertainty splatting module. <strong>Right:</strong> Through tile
            rasterization, we project raw colors, mapped colors, and uncertainties onto 2D visible planes. A boundary
            penalty finally refines the filtering mask in handling occlusions.
        </figcaption>
    </figure>
</section>
<!--<section>-->
<!--    <h2>Light Decoupling</h2>-->
<!--    <p>-->
<!--        We propose a light decoupling strategy to optimize appearance embeddings based on nexus kernels instead of-->
<!--        massive Gaussian primitives. This strategy accelerates reconstruction speeds while ensuring local color-->
<!--        consistency for finer textures.-->
<!--    </p>-->
<!--&lt;!&ndash;    <video class="video" style="aspect-ratio: 1920/1080" loop muted autoplay>&ndash;&gt;-->
<!--&lt;!&ndash;        <source src="/assets/ours-branden.mp4" type="video/mp4">&ndash;&gt;-->
<!--&lt;!&ndash;    </video>&ndash;&gt;-->
<!--    <figure>-->
<!--        <div class="video-wrapper">-->
<!--            <video class="video" style="aspect-ratio: 1920/1080; clip-path: inset(150px 80px 0px 180px);" loop muted autoplay>-->
<!--                <source src="/assets/ours-branden.mp4" type="video/mp4">-->
<!--            </video>-->
<!--&lt;!&ndash;            <span class="video-label video-label-with-fps">&ndash;&gt;-->
<!--&lt;!&ndash;            <span>3DGS<div class="video-fps">FPS: 7.7</div></span>&ndash;&gt;-->
<!--&lt;!&ndash;            <span>WildGaussians<div class="video-fps">FPS: 9.6</div></span>&ndash;&gt;-->
<!--&lt;!&ndash;          </span>&ndash;&gt;-->
<!--        </div>-->
<!--    </figure>-->
<!--    <figure>-->
<!--        <div class="video-wrapper">-->
<!--            <video class="video" style="aspect-ratio: 1920/1080; clip-path: inset(150px 100px 0px 200px);" loop muted autoplay>-->
<!--                <source src="/assets/ours-sacre.mp4" type="video/mp4">-->
<!--            </video>-->
<!--&lt;!&ndash;            <video class="video-compare" style="aspect-ratio: 1920/1080" loop muted>&ndash;&gt;-->
<!--&lt;!&ndash;                <source src="/assets/kplanes-wg-trevi.mp4" type="video/mp4">&ndash;&gt;-->
<!--&lt;!&ndash;            </video>&ndash;&gt;-->
<!--&lt;!&ndash;            <span class="video-label video-label-with-fps">&ndash;&gt;-->
<!--&lt;!&ndash;            <span>K-Planes<div class="video-fps">FPS: 0.15</div></span>&ndash;&gt;-->
<!--&lt;!&ndash;            <span>WildGaussians<div class="video-fps">FPS: 6.5</div></span>&ndash;&gt;-->
<!--&lt;!&ndash;          </span>&ndash;&gt;-->
<!--        </div>-->
<!--    </figure>-->
<!--    <figure>-->
<!--        <div class="video-wrapper">-->
<!--            <video class="video" style="aspect-ratio: 1920/1080; clip-path: inset(100px 80px 0px 150px);" loop muted autoplay>-->
<!--                <source src="/assets/ours-trevi.mp4" type="video/mp4">-->
<!--            </video>-->
<!--&lt;!&ndash;            <video class="video-compare" style="aspect-ratio: 1920/1080" loop muted>&ndash;&gt;-->
<!--&lt;!&ndash;                <source src="/assets/nerfwr-wg-sacrecoeur.webm" type="video/webm">&ndash;&gt;-->
<!--&lt;!&ndash;                <source src="/assets/nerfwr-wg-sacrecoeur.mp4" type="video/mp4">&ndash;&gt;-->
<!--&lt;!&ndash;            </video>&ndash;&gt;-->
<!--&lt;!&ndash;            <span class="video-label video-label-with-fps">&ndash;&gt;-->
<!--&lt;!&ndash;            <span>NeRF-W (reimpl.)<div class="video-fps">FPS: 0.004</div></span>&ndash;&gt;-->
<!--&lt;!&ndash;            <span>WildGaussians<div class="video-fps">FPS: 10.6</div></span>&ndash;&gt;-->
<!--&lt;!&ndash;          </span>&ndash;&gt;-->
<!--        </div>-->
<!--    </figure>-->
<!--</section>-->

<section>
    <h2>Concurrent works</h2>
    <p class="justify">
        There are several concurrent works that also aim to extend 3DGS to handle in-the-wild data:
        <ul>
            <li><a href="https://arxiv.org/pdf/2407.08447">WildGaussians: 3D Gaussian Splatting in the Wild</a></li>
            <li><a href="https://arxiv.org/pdf/2403.15704">Gaussian in the Wild: 3D Gaussian Splatting for Unconstrained
                Image Collections</a></li>
        </ul>
    </p>
</section>
<section>
    <h2>Acknowledgements</h2>
    <p class="justify">
        We sincerely appreciate the authors of <a href="https://github.com/graphdeco-inria/gaussian-splatting">3DGS</a> and
        <a href="https://github.com/nerfbaselines/nerfbaselines">NerfBaselines</a> for their great work and released code.
        Please follow their licenses when using our code.
    </p>
</section>
<section class="citation">
    <h2>Citation</h2>
    <span>Please use the following citation:</span>
    <pre><code>@article{tang2024nexussplats,
    title={NexusSplats: Efficient 3D Gaussian Splatting in the Wild},
    author={Tang, Yuzhou and Xu, Dejun and Hou, Yongjie and Wang, Zhenzhong and Jiang, Min},
    journal={arXiv preprint arXiv:2411.14514},
    year={2024}
}</code></pre>
</section>
<script src="/scripts.js"></script>
</body>
</html>
